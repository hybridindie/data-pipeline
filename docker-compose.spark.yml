version: '3.7'
x-core-common:
  &core-common
  depends_on:
    &core-common-depends-on
    redis:
      condition: service_healthy
    postgres:
      condition: service_healthy

x-spark-image:
  &spark-image apache/spark-py:v3.2.1
x-spark-common-environment:
    &spark-common-env
    JAVA_HOME: /usr/lib/jvm/java-11-openjdk-amd64/
    SPARK_LOCAL_DIRS: /opt/workspace
    SPARK_NO_DAEMONIZE: true
    SPARK_HOME: /opt/spark
    SPARK_MASTER_HOST: spark-master
    SPARK_MASTER_PORT: 7077
    SPARK_MASTER_OPTS: ""
    PYSPARK_PYTHON: python3
    SPARK_WORKER_CORES: 1
    SPARK_WORKER_MEMORY: 1024m

x-spark-worker:
  &spark-worker
  build:
    context: .
    dockerfile: ./docker/spark/Dockerfile
  image: spark
  environment: *spark-common-env
  command: ["/opt/spark/sbin/start-worker.sh", "spark://spark-master:7077"]
  volumes:
    - spark-workspace:/opt/workspace
  depends_on:
    - spark-master

services:
  ##############################################################################
  # Spark Services
  ##############################################################################
  spark-master:
    build:
      context: .
      dockerfile: ./docker/spark/Dockerfile
    image: spark
    container_name: spark-master
    environment: *spark-common-env
    ports:
      - 8070:8080
      - 7077:7077
    volumes:
      - spark-workspace:/opt/workspace
    command: ["/opt/spark/sbin/start-master.sh"]
    user: "0"
  spark-worker-1:
    <<: *spark-worker
    container_name: spark-worker-1
    ports:
      - 8071:8081
  spark-worker-2:
    <<: *spark-worker
    container_name: spark-worker-2
    ports:
      - 8072:8081

volumes:
  spark-workspace:
    name: "hdfs"
    driver: local
